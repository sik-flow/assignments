{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center\">Module 6 Assessment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your Mod 6 Assessment. You will be tested for your understanding on concepts and ability to programmatically solve problems that have been covered in class and in the curriculum. Topics in this assessment include graph theory, natural language processing, and neural networks. \n",
    "\n",
    "The goal here is to demonstrate your knowledge.  Showing that you know things is more important than getting the best model.\n",
    "\n",
    "Use any libraries you want to solve the problems in the assessment. \n",
    "\n",
    "You will have up to 90 minutes to complete this assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will attempt to classify text messages as \"SPAM\" or \"HAM\" using TF-IDF Vectorization. Once we successfully classify our texts we will examine our results to see which words are most important to each class of text messages. \n",
    "\n",
    "Complete the functions below and answer the question(s) at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "df_messages = pd.read_csv('data/spam.csv', usecols=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string labels to 1 or 0 \n",
    "le = LabelEncoder()\n",
    "df_messages['target'] = le.fit_transform(df_messages['v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  target\n",
       "0   ham  Go until jurong point, crazy.. Available only ...       0\n",
       "1   ham                      Ok lar... Joking wif u oni...       0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3   ham  U dun say so early hor... U c already then say...       0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine or data\n",
    "df_messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features and labels \n",
    "X = df_messages['v2']\n",
    "y = df_messages['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a list of stopwords \n",
    "stopwords_list = stopwords_list = stopwords.words('english') + list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1) Let's create a function that takes in our various texts along with their respective labels and uses TF-IDF to vectorize the texts.  Recall that TF-IDF helps us \"vectorize\" text (turn text into numbers) so we can do \"math\" with it.  It is used to reflect how relevant a term is in a given document in a numerical way. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tf-idf vectorization (use sklearn's TfidfVectorizer) for our data\n",
    "def tfidf(X, y,  stopwords_list): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
    "    tf_idf_train = vectorizer.fit_transform(X_train)\n",
    "    tf_idf_test = vectorizer.transform(X_test)\n",
    "    return tf_idf_train, tf_idf_test, y_train, y_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train, tf_idf_test, y_train, y_test, vecotorizer = tfidf(X, y, stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2) Now that we have a set of vectorized training data we can use this data to train a classifier to learn how to classify a specific text based on the vectorized version of the text. Below we have initialized a simple Naive Bayes Classifier and Random Forest Classifier. Complete the function below which will accept a classifier object, a vectorized training set, vectorized test set, and list of training labels and return a list of predictions for our training set and a separate list of predictions for our test set.</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that takes in a classifier and trains it on our tf-idf vectors and generates test and train predictiions\n",
    "def classify_text(classifier, tf_idf_train, tf_idf_test, y_train):\n",
    "    classifier.fit(tf_idf_train, y_train)\n",
    "    train_preds = classifier.predict(tf_idf_train)\n",
    "    test_preds = classifier.predict(tf_idf_test)\n",
    "    return train_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions for Naive Bayes Classifier\n",
    "nb_train_preds, nb_test_preds = classify_text(nb_classifier,tf_idf_train, tf_idf_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1202    0]\n",
      " [  44  147]]\n",
      "0.968413496051687\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, nb_test_preds))\n",
    "print(accuracy_score(y_test, nb_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate predictions for Random Forest Classifier\n",
    "rf_train_preds, rf_test_preds = classify_text(rf_classifier,tf_idf_train, tf_idf_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1201    1]\n",
      " [  35  156]]\n",
      "0.9741564967695621\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rf_test_preds))\n",
    "print(accuracy_score(y_test, rf_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see both classifiers do a pretty good job classifying texts as either \"SPAM\" or \"HAM\". Let's figure out which words are the most important to each class of texts! Recall that Inverse Document Frequency can help us determine which words are most important in an entire corpus or group of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(class_, df, stopwords_list):\n",
    "    docs = df[df.v1==class_].v2\n",
    "    class_dict = {} \n",
    "    for doc in docs:\n",
    "        words = set(doc.split())\n",
    "        for word in words:\n",
    "            if word.lower() not in stopwords_list: \n",
    "                class_dict[word.lower()] = class_dict.get(word.lower(), 0) + 1\n",
    "    idf_df = pd.DataFrame.from_dict(class_dict, orient='index')\n",
    "    idf_df.columns = ['IDF']\n",
    "    idf_df.IDF = len(docs)/idf_df.IDF\n",
    "    idf_df = idf_df.sort_values(by=\"IDF\", ascending=True)\n",
    "    return idf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>2.277439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>4.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>5.574627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.746154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>6.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>7.047170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile</th>\n",
       "      <td>7.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>7.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>7.182692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply</th>\n",
       "      <td>7.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             IDF\n",
       "call    2.277439\n",
       "free    4.698113\n",
       "txt     5.574627\n",
       "2       5.746154\n",
       "ur      6.073171\n",
       "u       7.047170\n",
       "mobile  7.114286\n",
       "text    7.114286\n",
       "claim   7.182692\n",
       "reply   7.781250"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_idf('spam', df_messages, stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>7.310606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i'm</th>\n",
       "      <td>14.067055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>17.481884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.188285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>22.133028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>22.133028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;lt;#&amp;gt;</th>\n",
       "      <td>22.546729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>23.309179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>23.309179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>23.651961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 IDF\n",
       "u           7.310606\n",
       "i'm        14.067055\n",
       "get        17.481884\n",
       "2          20.188285\n",
       "go         22.133028\n",
       "got        22.133028\n",
       "&lt;#&gt;  22.546729\n",
       "call       23.309179\n",
       "like       23.309179\n",
       "come       23.651961"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_idf('ham', df_messages, stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain\n",
    "The word school(s) has the highest TF-IDF value in the second document of our test data. What does that tell us about the word school? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The word, school is very unique. It is not found frequently across many documents but its present in the second document meaning it has significant importance to this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis Assessment\n",
    "\n",
    "For these next questions, you'll be using a graph dataset of facebook users and networkx. In the next cell, we're going to read in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.read_edgelist('./data/0.edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1) Create a function `find_centrality` that returns a dictionary with the user with the highest betweenness centrality and the user with the highest degree centrality. It should return a dictionary that looks like:\n",
    "\n",
    "\n",
    "{'bc' : |user|, 'dc' : |user|}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centrality(graph):\n",
    "    bc = nx.algorithms.centrality.betweenness_centrality(G)\n",
    "    max_bc = max(bc.items(), key = lambda kv : kv[1] )\n",
    "    print('betweenness centrality: ',max_bc)\n",
    "    dc = nx.algorithms.centrality.degree_centrality(G)\n",
    "    max_dc = max(dc.items(), key= lambda kv : kv[1])\n",
    "    print('degree centrality: ', max_dc)\n",
    "    centrality_dict = {'bc':max_bc[0],'dc':max_dc[0]}\n",
    "    return centrality_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betweenness centrality:  ('277', 0.2658578437822957)\n",
      "degree centrality:  ('56', 0.23192771084337352)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bc': '277', 'dc': '56'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) How does each of these people wield influence on the network? Imagine a message had to get to people from different communities. Who would be the best user to deliver the message to ensure that people from opposite communities receive the message?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The user with the highest degree centrality has the most overall connections. The user with the highest betweenness centrality has the most connections go through them. The user with the highest betweenness centrality (277) would be the best person to ensure that people from disparate communities receive the message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) A marketing group is looking to target different communities with advertisements based off of their assumed mutual interests. Use the k_cliques_communities method to calculate the number of cliques formed with k users in a function `find_k_communities`. Calculate how many communities there are if the minimum size of a clique is 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_communities(graph,k):\n",
    "    return len(list(nx.algorithms.community.kclique.k_clique_communities(graph,k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_k_communities(G,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Assessment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep learning portion of this assessment is split into three main sections.  First, concepts from the introduction to deep learning are assessed by reconstructing the basic building blocks of a neural network.  Then, forward and back-propagation will be discussed in the “Multilayer Perceptron” section, as we build out a fully functioning neural network.\n",
    "\n",
    "Finally, you will be tuning and optimizing two neural networks trained on data generated with SKLearn — the first with regularization, and the second by modifying different aspects of the gradient descent process for deep learning.  You will receive credit for explaining your steps well even if the model does not improve much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_gaussian_quantiles, make_circles\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential, regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>The Sigmoid Function</b></center>\n",
    "$$ \\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/perceptron.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) What are the inputs and outputs of a perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs are either exogenous variables or outputs of other perceptrons.  The output is the result of the multiplication of weights and biases, the addition of a bias term, and then transformation via an activation function e.g. the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Given inputs and weights 1 through l and the sigmoid function (given above), write a function which computes the output y. Assume bias = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(input_function):\n",
    "    return 1/(1+np.exp(-1*input_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_output(x,w,b=0):\n",
    "    #b is not necessary, but no points off if they include it\n",
    "    return sigmoid(b+np.sum(np.multiply(x,w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) What is the role of the sigmoid function here? How does what it does here relate to logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The sigmoid function scales the perceptron output to between 0 and 1.  The sigmoid is also used in logistic regression to turn a continuous output into a 0-or-1 classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Name two other activation functions and write functions for them as done with the sigmoid in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_1(input_function):\n",
    "    #RELU\n",
    "    if input_function>0:\n",
    "        return input_function\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_2(input_function):\n",
    "    #TANH\n",
    "    return np.tanh(input_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Relu and hyperbolic tangent are two other examples of activation functions.\n",
    "\n",
    "Also: inverse tangent, softmax, linear, exponential, and many more.\n",
    "\n",
    "Several examples here: https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/Deeper_network_day2.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward propagation\n",
    "\n",
    "$ Z^{[l]}= W^{[l]} A^{[l-1]} + b^{[l]}$\n",
    "\n",
    "$ A^{[l]}= g^{[l]} ( Z^{[l]})$\n",
    "\n",
    "##### Back-propagation\n",
    "$ dZ^{[l]}= dA ^{[l]} * g^{[l]'} (Z^{[l]})$\n",
    "\n",
    "$ dW^{[l]} = \\dfrac{1}{m} dZ^{[l]}* A^{[l-1]T}$\n",
    "\n",
    "$ db^{[l]} = \\dfrac{1}{m} np.sum(dZ^{[l]}, axis=1, keepdims=True)$\n",
    "\n",
    "$ dA^{[l-1]} = W^{[l]T}*dZ^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Describe the process of forward propagation in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Outputs of each perceptron are propagated to each node of the next layer and scaled by weights specific to each of these connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) How does what happens in forward-propagation change what happens in back-propagation? Be as specific as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Each time the neural network propagates forward for a given batch, there are residuals due to inaccuracy.  To update the weights and biases in the network, the derivatives of each term are calculated using these residuals and then simultaneously updated using the process of gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Why is the chain rule important for backpropagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The chain rule is a rule for finding the derivative of a function which encapsulates another function.  This is important for backpropagation because residuals are the result of several transformations by the time they arise at the outuput layer.  The chain rule is applied recurssively for each layer in the neural network to get the derivatives which determine weight and bias updates in backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) You are training a neural network to pick out particular sounds in a dataset of audio files. Assume all preprocessing has already been done. If there are several sounds in each mp3 file, how would you modify your output layer to identify whether a particular sound occurs? How does your interpretation change assuming more than one sound can be in each file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "This is a multi-label problem.  There should be one output for each label.  If a specific output node is over a certain threshold, then that node's label is assigned to that observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization and Optimization of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets are created using SKLearn, and should be improved. Although changing the number of nodes and layers may improve the models, focus on regularization in the first dataset, and gradient descent in the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=450, noise=0.12)\n",
    "df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'teal', 1:'orange'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    if key != 2:\n",
    "        group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization: The following model is over-fit. Modify the following code to address the discrepancy between train and test accuracy.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test/split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Modify the code below to use L2 regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code goes in the cell below. Try running once without regularization first and look at what happens to train and test accuracy.\n",
    "\n",
    "Hint: use the activity_regularizer parameter in both of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2da8fa58>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "#Instantiate Classifier\n",
    "classifier = Sequential()\n",
    "\n",
    "#Hidden Layer\n",
    "classifier.add(Dense(\n",
    "    32, \n",
    "    activation='relu', \n",
    "    input_dim=2,\n",
    "    kernel_initializer='random_normal',\n",
    "    activity_regularizer = 'l2'\n",
    "))\n",
    "\n",
    "#Hidden Layer\n",
    "classifier.add(Dense(\n",
    "    32,\n",
    "    activation='relu', \n",
    "    input_dim=2,\n",
    "    kernel_initializer='random_normal',\n",
    "    activity_regularizer = 'l2'\n",
    "))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(\n",
    "    1, \n",
    "    activation='sigmoid',\n",
    "    kernel_initializer='random_uniform',\n",
    "))\n",
    "\n",
    "classifier.compile(optimizer ='adam',loss=\"binary_crossentropy\",metrics =['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs=25, verbose=0, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look what happens to train and test accuracy as you modify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "#predict classes\n",
    "predicted_vals_train = classifier.predict_classes(X_train)\n",
    "#show accuracy score\n",
    "print(accuracy_score(y_train,predicted_vals_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "#predict classess\n",
    "predicted_vals_test = classifier.predict_classes(X_test)\n",
    "#show accuracy score\n",
    "print(accuracy_score(y_test,predicted_vals_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Explain what you did and how it changed the train and test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "A weight penalization term was added for the two hidden layers.  Train accuracy went down, but test accuracy went up, meaning that overfitting was decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Explain what regularization does, and how it affects the final weights of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Regularization penalizes high weights by modifying the cost function, which can help reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) How does L1 regularization change a neural network's architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "L1 regularization may eliminate connections between nodes entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization with Gradient Descent\n",
    "\n",
    "A 3 dimensional dataset is generated using SKlearn and a poorly fit neural network is fit to it. Try improving the model using what's available through Keras, and then explain what you did in part 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/data.png' width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 3d data with complex error surface for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Construct dataset\n",
    "# Gaussian 1\n",
    "X1, y1 = make_gaussian_quantiles(cov=3.,\n",
    "                                 n_samples=10000, n_features=3,\n",
    "                                 n_classes=2, random_state=1)\n",
    "X1 = pd.DataFrame(X1,columns=['x','y','z'])\n",
    "y1 = pd.Series(y1)\n",
    "\n",
    "# Gaussian 2\n",
    "X2, y2 = make_gaussian_quantiles(mean=(4, 4,2), cov=1,\n",
    "                                 n_samples=5000, n_features=3,\n",
    "                                 n_classes=2, random_state=2)\n",
    "X2 = pd.DataFrame(X2,columns=['x','y','z'])\n",
    "y2 = pd.Series(y2)\n",
    "# Combine the gaussians\n",
    "X1.shape\n",
    "X2.shape\n",
    "X = pd.DataFrame(np.concatenate((X1, X2)))\n",
    "y = pd.Series(np.concatenate((y1, - y2 + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Modify the code below to improve the starter model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: use help(Dense) to see what parameters you can change. You should be able to explain how these parameters relate to gradient descent. Don't worry too much about overfitting in this example, just focus on gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), input_dim=3))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None)))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network, and specifying to measure accuracy at each step\n",
    "classifier.compile(optimizer ='adam',loss='poisson', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.8466 - acc: 0.5011\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.8465 - acc: 0.5104\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.8463 - acc: 0.5377\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.8459 - acc: 0.5725\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.8449 - acc: 0.5861\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.8423 - acc: 0.6076\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 0.8374 - acc: 0.6387\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.8287 - acc: 0.6598\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.8025 - acc: 0.7192\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.7705 - acc: 0.7471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e2f9080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the neural network\n",
    "classifier.fit(X,y, batch_size=5, epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Explain why modifying the gradient descent process does anything and how it works.  Include parameters you tried even if they did not improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "1. kernel_initializer - changing this term can chang where the model converges, due to local minima.  A different minimum for the cost function can be reached if weight start differently.\n",
    "2. batch size - this is the number of observations the model is trained on in each iteration.  \n",
    "3. loss - changing the loss function changes residuals and therefore backpropagation.\n",
    "4. optimizer - changes how the learning rate is adjusted\n",
    "\n",
    "Students may come up with more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
